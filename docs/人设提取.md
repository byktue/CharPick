https://github.com/LC1332/Chat-Haruhi-Suzumiya/tree/main/characters/novel_collecting#%E5%B0%8F%E8%AF%B4%E4%B8%AD%E5%AF%B9%E8%AF%9D%E6%8A%BD%E5%8F%96%E5%B7%A5%E5%85%B7
ChatHaruhi 的仓库太过混乱，寻找其他办法提取人设

[[CharPick_TODO]]

### 1. 使用 `LangExtract` (Google 开源的最新提取库)
这是 2025 年非常流行的轻量级库，专门用于从非结构化文本（如小说）中提取结构化信息。
- **做法：** 你只需定义一个 `Character` 模型（包含姓名、性格、外号、关系），给它 1-2 个小说片段作为示例，它就能自动扫描全书。
- **代码示例：**
```python
import langextract as lx
# 定义你想要的提取模板
schema = {
    "name": "人物姓名",
    "personality": "性格特征",
    "relationships": [{"target": "对方姓名", "type": "关系类型"}]
}
# 传入小说文本进行提取
results = lx.extract(text=novel_chapter, schema=schema)
```

### 2. 借用 `CharacterGLM` 或 `RoleLLM` 的数据清洗脚本
ChatHaruhi 的很多数据来源于 **RoleLLM** 项目。你可以直接去搜 `RoleLLM` 的 GitHub 仓库，那里有专门的脚本将原始小说/剧本转为 `JSONL` 格式的角色档案，比 ChatHaruhi 的主仓库更纯粹。

## 手动构建“小说人物提取器”的 3 步走
如果你想自己写一个简单的脚本，可以遵循这个最有效的工程路径：
### 第一步：人物发现 (Entity Discovery)
先用 **BookNLP**（适合英文）或 **HanLP/LTP**（适合中文）扫描全书，统计出现频率最高的人名。
> **提示：** 这一步不要用大模型，太贵且慢。用传统的 NLP 库跑，效率极高。
### 第二步：角色画像刻画 (Profiling)
针对第一步发现的高频人物，利用大模型的 **Long Context（长上下文）** 能力：
- **输入：** 包含该人物关键词的上下文切片（约 5k-10k token）。
- **提示词：** “你是一个文学分析师，请根据以下文本，总结角色‘张无忌’的性格、武功、以及他与其他人的情感纠葛，并以 JSON 格式输出。”
### 第三步：关系图谱连接 (Graph Linking)
将提取出的 JSON 存入图数据库（如 Neo4j）或简单的 JSON 库，这就成了你的角色库基础。



| **项目名称**         | **本质属性**            | **核心功能**                | **适用场景**                         |
| ---------------- | ------------------- | ----------------------- | -------------------------------- |
| **LangExtract**  | **工具库** (Google 开发) | 将混乱的文本提取成**结构化 JSON**   | **提取阶段：** 快速从几万字小说中抓取人名、性格、关系。   |
| **CharacterGLM** | **大模型** (智谱/清华)     | 专门针对**中文角色扮演**训练的模型     | **对话阶段：** 提取完数据后，用这个模型作为底座来“演戏”。 |
| **RoleLLM**      | **全流程框架**           | 包含数据构建、模型训练、评测的**技术方案** | **研究阶段：** 学习如何从海量剧本中系统化生成角色语料库。  |

