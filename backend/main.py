from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import json
import asyncio
import time
from backend.long import advanced_split_novel, get_ollama_embedding, local_model, EXAMPLES

app = FastAPI(title="CHARPICK API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class ExtractionRequest(BaseModel):
    file_name: str
    prompt: str

# --- æ—¥å¿—è¾…åŠ©åŠŸèƒ½ ---
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
LOG_FILE = os.path.join(BASE_DIR, "output", "process.log")
OUTPUT_FILE = os.path.join(BASE_DIR, "output", "charpick_v3_database.jsonl")

def write_log(message: str):
    """åŒæ—¶æ‰“å°åˆ°ç»ˆç«¯å¹¶å†™å…¥æ—¥å¿—æ–‡ä»¶"""
    print(message)
    # ç¡®ä¿ output ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
    timestamp = time.strftime("%H:%M:%S", time.localtime())
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {message}\n")

# --- ä¿®æ”¹åçš„åå°ä»»åŠ¡ ---
def background_extraction_task(file_path: str, custom_prompt: str):
    write_log(f"ğŸš€ å¼€å§‹ä»»åŠ¡: å¤„ç†æ–‡ä»¶ {os.path.basename(file_path)}")
    try:
        chapters = advanced_split_novel(file_path)
        write_log(f"ğŸ“š å°è¯´åˆ‡åˆ†å®Œæˆï¼Œå…± {len(chapters)} ç« ")
        
        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

        with open(OUTPUT_FILE, "a", encoding="utf-8") as f_out:
            for idx, chapter in enumerate(chapters):
                write_log(f"â³ æ­£åœ¨å¤„ç†: {chapter['title']} ({idx+1}/{len(chapters)})...")
                
                chunk_text = f"{chapter['title']}\n{chapter['content'][:3500]}"
                try:
                    # å°è¯•ä½¿ç”¨ langextract
                    try:
                        import langextract as lx
                        result = lx.extract(
                            text_or_documents=chunk_text,
                            prompt_description=custom_prompt,
                            examples=EXAMPLES,
                            model=local_model
                        )
                        extraction_data = result.extractions[0].attributes if result.extractions else {}
                    except Exception as e:
                        extraction_data = {"note": "æå–å¤±è´¥æˆ–åº“ä¸å¯ç”¨", "error": str(e)}

                    # å‘é‡åŒ–
                    plot_text = extraction_data.get("plot_summary", "") if isinstance(extraction_data, dict) else ""
                    vector = get_ollama_embedding(plot_text) if plot_text else []

                    record = {
                        "id": idx, 
                        "title": chapter['title'], 
                        "metadata": extraction_data, 
                        "vector": vector
                    }
                    f_out.write(json.dumps(record, ensure_ascii=False) + "\n")
                    f_out.flush() # ç¡®ä¿ç«‹å³å†™å…¥ç£ç›˜
                    write_log(f"âœ… å®Œæˆ: {chapter['title']}")
                    
                except Exception as e:
                    write_log(f"âŒ ç« èŠ‚å¤„ç†å¤±è´¥: {chapter['title']} - {str(e)}")
        
        write_log("ğŸ‰ æ‰€æœ‰ç« èŠ‚æå–ä»»åŠ¡å·²å®Œæˆï¼")
        
    except Exception as e:
        write_log(f"ğŸ’¥ è‡´å‘½é”™è¯¯: {str(e)}")

# --- æ–°å¢ï¼šå®æ—¶æ—¥å¿—æµæ¥å£ ---
@app.get("/logs")
async def log_stream():
    async def log_generator():
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆåˆ›å»º
        if not os.path.exists(LOG_FILE):
            with open(LOG_FILE, "w", encoding="utf-8") as f:
                f.write("[System] Log stream started...\n")
        
        # æ‰“å¼€æ–‡ä»¶å¹¶ç§»åŠ¨åˆ°æœ«å°¾ (åªè¯»å–æ–°æ—¥å¿—)
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            f.seek(0, 2) 
            
            while True:
                line = f.readline()
                if line:
                    # SSE æ ¼å¼: data: <content>\n\n
                    yield f"data: {line}\n\n"
                else:
                    await asyncio.sleep(0.5) # æ²¡æœ‰æ–°æ—¥å¿—æ—¶ç­‰å¾…
                    
    return StreamingResponse(log_generator(), media_type="text/event-stream")


# --- åŸæœ‰æ¥å£ ---
@app.get("/files")
def list_files():
    data_dir = os.path.join(BASE_DIR, "data")
    if not os.path.exists(data_dir):
        return []
    return [f for f in os.listdir(data_dir) if f.endswith('.txt')]

@app.post("/start-extraction")
async def start(req: ExtractionRequest, background_tasks: BackgroundTasks):
    file_path = os.path.join(BASE_DIR, "data", req.file_name)
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    # æ¸…ç©ºæ—§æ—¥å¿— (å¯é€‰ï¼Œçœ‹ä½ æ˜¯å¦æƒ³ä¿ç•™å†å²)
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        f.write(f"[System] æ–°ä»»åŠ¡å¯åŠ¨ - {req.file_name}\n")
        
    background_tasks.add_task(background_extraction_task, file_path, req.prompt)
    return {"status": "started"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
